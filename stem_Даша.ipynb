{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "sH3qmcB37j18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28E8nJu_8Irj",
        "outputId": "1ad98c19-ea81-42e5-fadd-7479527cda4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.А. Сегментация по символам**"
      ],
      "metadata": {
        "id": "j5-f7lNP5NUe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTpYff3-3Thv",
        "outputId": "abf7fc09-7b76-4667-ceb4-1aa5cf5f33da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['З', 'а', 'д', 'а', 'н', 'и', 'е', ' ', '1', '.', 'А', '.', ' ', 'С', 'е', 'г', 'м', 'е', 'н', 'т', 'а', 'ц', 'и', 'я', ' ', 'п', 'о', ' ', 'с', 'и', 'м', 'в', 'о', 'л', 'а', 'м', '.']\n"
          ]
        }
      ],
      "source": [
        "text = \"Задание 1.А. Сегментация по символам.\"\n",
        "symb = [x for x in text]\n",
        "print(symb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Б. Сегментация по токенам**"
      ],
      "metadata": {
        "id": "FlQKg7vX5aL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text = \"Задание 1.А. Сегментация по символам.\"\n",
        "tokenize = word_tokenize(text)\n",
        "print(tokenize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmxUEWLf5fHQ",
        "outputId": "ecca841f-0637-48b3-af75-803b2f2da674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Задание', '1.А', '.', 'Сегментация', 'по', 'символам', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.В. Сегментация по предложениям**"
      ],
      "metadata": {
        "id": "pGvr3ON25fbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text = \"Задание один В. В процессе. Почти сделал.\"\n",
        "sent = sent_tokenize(text, language=\"russian\")\n",
        "print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qw5jG02j5jK1",
        "outputId": "292e6f60-80cd-4246-93fb-fdcec6abf73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Задание один В. В процессе.', 'Почти сделал.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.А. Стемминг для списка слов**"
      ],
      "metadata": {
        "id": "xPhd2F0r5lBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "snowball = SnowballStemmer(language=\"english\")\n",
        "lancaster = LancasterStemmer()\n",
        "regexp = RegexpStemmer(\"ing$|s$|e$|able$|ety$|ous$|\", min=4)\n",
        "\n",
        "word_list = [\"impression\", \"impress\", \"impressive\", \"impressible\", \"impressions\"]\n",
        "\n",
        "print(\"{0:20}{1:20}{2:20}{3:30}{4:40}\".format(\"Word\", \"Porter Stemmer\", \"Snowball Stemmer\", \"Lancaster Stemmer\", \"Regexp Stemmer\"))\n",
        "\n",
        "for word in word_list:\n",
        "  print(\"{0:20}{1:20}{2:20}{3:30}{4:40}\".format(word, porter.stem(word), snowball.stem(word), lancaster.stem(word), regexp.stem(word)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOPBHVI_5qxg",
        "outputId": "13866a58-52f5-4d63-d5c5-5b6342498481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Snowball Stemmer    Lancaster Stemmer             Regexp Stemmer                          \n",
            "impression          impress             impress             impress                       impression                              \n",
            "impress             impress             impress             impress                       impres                                  \n",
            "impressive          impress             impress             impress                       impressiv                               \n",
            "impressible         impress             impress             impress                       impressibl                              \n",
            "impressions         impress             impress             impress                       impression                              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*2.A.Русский.*"
      ],
      "metadata": {
        "id": "tfYkfCKdGxDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "snowball = SnowballStemmer(language=\"russian\")\n",
        "\n",
        "word_list = [\"радуга\", \"радужный\", \"радует\", \"рад\", \"радуги\", \"радовать\"]\n",
        "\n",
        "for word in word_list:\n",
        "  print(\"{0:20}{1:20}\".format(word, snowball.stem(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v7plPwQG39A",
        "outputId": "0cb119e1-66fe-4f9d-fe8a-464bd86bba84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "радуга              радуг               \n",
            "радужный            радужн              \n",
            "радует              рад                 \n",
            "рад                 рад                 \n",
            "радуги              радуг               \n",
            "радовать            радова              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*2.А.Итальянский.*"
      ],
      "metadata": {
        "id": "vXww5I3mG4Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "snowball = SnowballStemmer(language=\"italian\")\n",
        "\n",
        "word_list = [\"porta\", \"porte\", \"portale\", \"portare\", \"portone\", \"portiera\"]\n",
        "\n",
        "for word in word_list:\n",
        "  print(\"{0:20}{1:20}\".format(word, snowball.stem(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5CuxtilIiJ2",
        "outputId": "0c5750a1-338d-4fc2-80d8-b066df1000a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "porta               port                \n",
            "porte               port                \n",
            "portale             portal              \n",
            "portare             port                \n",
            "portone             porton              \n",
            "portiera            portier             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Б. Стемминг для текста**"
      ],
      "metadata": {
        "id": "J2u9B_GP5rCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "snowball = SnowballStemmer(language=\"english\")\n",
        "lancaster= LancasterStemmer()\n",
        "regexp = RegexpStemmer(\"ing$|s$|e$|able$|ety$|ous$|er$|ed$\", min=4)\n",
        "\n",
        "sentence_eng = \"Scientists have made a scientific discovery that they will teach others as teachers.\"\n",
        "word_list_eng = word_tokenize(sentence_eng)\n",
        "\n",
        "print(\"{0:20}{1:20}{2:20}{3:30}{4:40}\".format(\"Word\", \"Porter Stemmer\", \"Snowball Stemmer\", \"Lancaster Stemmer\", \"Regexp Stemmer\"))\n",
        "\n",
        "for word in word_list_eng:\n",
        "  print(\"{0:20}{1:20}{2:20}{3:30}{4:40}\".format(word,porter.stem(word), snowball.stem(word), lancaster.stem(word), regexp.stem(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb46JWF25yt5",
        "outputId": "ab14d1e9-cad7-4499-dc67-5e30383df39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Snowball Stemmer    Lancaster Stemmer             Regexp Stemmer                          \n",
            "Scientists          scientist           scientist           sci                           Scientist                               \n",
            "have                have                have                hav                           hav                                     \n",
            "made                made                made                mad                           mad                                     \n",
            "a                   a                   a                   a                             a                                       \n",
            "scientific          scientif            scientif            sci                           scientific                              \n",
            "discovery           discoveri           discoveri           discovery                     discovery                               \n",
            "that                that                that                that                          that                                    \n",
            "they                they                they                they                          they                                    \n",
            "will                will                will                wil                           will                                    \n",
            "teach               teach               teach               teach                         teach                                   \n",
            "others              other               other               oth                           other                                   \n",
            "as                  as                  as                  as                            as                                      \n",
            "teachers            teacher             teacher             teach                         teacher                                 \n",
            ".                   .                   .                   .                             .                                       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*2.Б.Русский.*"
      ],
      "metadata": {
        "id": "O7BkgoFNLwyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "snowball = SnowballStemmer(language=\"russian\")\n",
        "\n",
        "sentence_ru = \"Ученые сделали научное открытие, которому они будут учить других, как учителя.\"\n",
        "word_list_ru = word_tokenize(sentence_ru)\n",
        "\n",
        "for word in word_list_ru:\n",
        "  print(\"{0:20}{1:20}\".format(word, snowball.stem(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td7fFsxELxMx",
        "outputId": "b74482ed-05f3-4103-9559-fea60cac19d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ученые              учен                \n",
            "сделали             сдела               \n",
            "научное             научн               \n",
            "открытие            открыт              \n",
            ",                   ,                   \n",
            "которому            котор               \n",
            "они                 он                  \n",
            "будут               будут               \n",
            "учить               уч                  \n",
            "других              друг                \n",
            ",                   ,                   \n",
            "как                 как                 \n",
            "учителя             учител              \n",
            ".                   .                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*2.Б.Итальянский*"
      ],
      "metadata": {
        "id": "6nJaSyczLxme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "snowball = SnowballStemmer(language=\"italian\")\n",
        "\n",
        "sentence_it = \"Gli scienziati hanno fatto una scoperta scientifica che insegneranno ad altri come insegnanti.\"\n",
        "word_list_it = word_tokenize(sentence_it)\n",
        "\n",
        "for word in word_list_it:\n",
        "  print(\"{0:20}{1:20}\".format(word, snowball.stem(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ_elNG-Lx0x",
        "outputId": "24c39145-2604-42f7-b90a-efef6284b4ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gli                 gli                 \n",
            "scienziati          scienz              \n",
            "hanno               hann                \n",
            "fatto               fatt                \n",
            "una                 una                 \n",
            "scoperta            scopert             \n",
            "scientifica         scientif            \n",
            "che                 che                 \n",
            "insegneranno        insegn              \n",
            "ad                  ad                  \n",
            "altri               altri               \n",
            "come                com                 \n",
            "insegnanti          insegn              \n",
            ".                   .                   \n"
          ]
        }
      ]
    }
  ]
}